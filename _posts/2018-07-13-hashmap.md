---
layout:     post
title:      "Java集合之hashmap"
subtitle:   " \"hashmap源码分析\""
date:       2018-07-13 23:00:00
author:     "Mr.Xu"
header-img: "img/post-bg-2018.png"
catalog: true
tags:
    - java
---

```
* Hash table based implementation of the <tt>Map</tt> interface.  This
 * implementation provides all of the optional map operations, and permits
 * <tt>null</tt> values and the <tt>null</tt> key.  (The <tt>HashMap</tt>
 * class is roughly equivalent to <tt>Hashtable</tt>, except that it is
 * unsynchronized and permits nulls.)  This class makes no guarantees as to
 * the order of the map; in particular, it does not guarantee that the order
 * will remain constant over time.
 * =======================================================================
 * 基于hash表实现了map接口，这个实现类提供了map接口所有的方法，而且它允许key
 * 和values值都为空，（也就是说HashMap类和Hashtable类大致相当，除了它是线程不
 * 安全的且允许key和values值为空）。这个类不能保证map内部数据的顺序；通常，它
 * 也不能保证随着时间的变化，顺序保持不变。
 * ========================================================================= 
 * 这个意思也就是说我们往hashmap集合里通过put方法依次存入5个键值对的时候
 * （简化起见，用1,2,3,4,5来表示），显示结果可能是2,1,4,5,3(不能保证映射顺序)。
 * 在继续往集合添加数据的时候，当数组长度因集合扩容而改变时，会重新给原来的数
 * 据分配hashcode值，这个时候原来的2,1,4,5,3的顺序会改变（随机）。
```

- **要点：允许key及value为空；由于扩容后的重hash计算，原来的结构顺序会被改变**

```
 * <p>This implementation provides constant-time performance for the basic
 * operations (<tt>get</tt> and <tt>put</tt>), assuming（假如） the hash function
 * disperses the elements properly among the buckets.  Iteration over collection
 * views requires time proportional（与...成比例） to the "capacity" of the
 * <tt>HashMap</tt> instance (the number of buckets) plus its size (the number
 * of key-value mappings).  Thus, it's very important not to set the initial
 * capacity too high (or the load factor too low) if iteration performance is
 * important.
 * =========================================================================
 * 如果hash操作将所有元素放在hash桶中合适的地方,那么该实现则可以提供常数时间
 * 内执行get或put的操作. 如果想迭代整个集合视图,花费的时间与(HashMap实例的容量
 * (桶的数量)加上它的大小(键值对的数量))成正比. 因此,如果注重迭代性能,切记不
 * 要将初始容量设置得太高(或将加载因子设置得太低).
```

- **要点：初始化容量及加载因子要按实际情况设定。（一般不会改变加载因子的大小）**

```
 * <p>An instance of <tt>HashMap</tt> has two parameters that affect its
 * performance: <i>initial capacity</i> and <i>load factor</i>.  The
 * <i>capacity</i> is the number of buckets in the hash table, and the initial
 * capacity is simply the capacity at the time the hash table is created.  The
 * <i>load factor</i> is a measure of how full the hash table is allowed to
 * get before its capacity is automatically increased.  When the number of
 * entries in the hash table exceeds the product of the load factor and the
 * current capacity, the hash table is <i>rehashed</i> (that is, internal data
 * structures are rebuilt) so that the hash table has approximately twice the
 * number of buckets.
 * ===========================================================================
 * 一个HashMap的实例有两个参数影响它的性能：初始化容量和加载因子。容量（capacity）
 * 是哈希表中桶的数量（也就是数组长度），初始容量也就是哈希表被创建时的容量。
 * 加载因子（load factor）是决定容量自动增长到什么程度时，才自动扩容。
 * 如果哈希表中的条目数量（entries）超过了加载因子和当前容量的乘积时候，
 * 哈希表会被rehashed（也就是说，初始的数据结构会被重建），然后哈希表中桶的
 * 数量大约是原来的两倍（容量扩容为原来的两倍）。
```

- **要点：介绍扩容机制，触发扩容条件后，数组长度扩容为原来的两倍。**

```
 * <p>As a general rule, the default load factor (.75) offers a good
 * tradeoff between time and space costs.  Higher values decrease the
 * space overhead but increase the lookup cost (reflected in most of
 * the operations of the <tt>HashMap</tt> class, including
 * <tt>get</tt> and <tt>put</tt>).  The expected number of entries in
 * the map and its load factor should be taken into account when
 * setting its initial capacity, so as to minimize the number of
 * rehash operations.  If the initial capacity is greater than the
 * maximum number of entries divided by the load factor, no rehash
 * operations will ever occur.
 * ==================================================================
 * 作为一个通常的规则，默认的初始化加载因子是0.75，在时间和空间的损耗上
 * 它提供了一个较好的折衷。较高的值会减小空间的开销，但是会增加查找成本（
 * 它反映在HashMap的大部分方法中，包括get和put方法）。当设置初始化容量时，
 * 应该把预期的条目数量和加载因子考虑在，那样可以最小化数据被重哈希的次数。
 * 如果初始化的容量比 （条目总数/加载因子）还要大，就不会发生重哈希操作。
```

- **要点：介绍加载因子为什么默认取值为0.75，时间和空间上的折衷。**

```
* <p>If many mappings are to be stored in a <tt>HashMap</tt>
 * instance, creating it with a sufficiently large capacity will allow
 * the mappings to be stored more efficiently than letting it perform
 * automatic rehashing as needed to grow the table.  Note that using
 * many keys with the same {@code hashCode()} is a sure way to slow
 * down performance of any hash table. To ameliorate impact, when keys
 * are {@link Comparable}, this class may use comparison order among
 * keys to help break ties.
 * ==================================================================
 * 如果有大量的映射存储在一个HashMap的实例中，比起让JVM自动扩容，创建
 * 一个足够大的初始容量会让这些映射存储的更加高效。注意，如果有很多的
 * keys值使用一个相同的hash值，毫无疑问，这会降低hash表的性能。为了减轻
 * 它的影响，让这些key值实现Comparable接口，这个类可以通过比较指令来减轻影响。
 * ===========================================================================	
 * Why？ 如果实现了Comparable接口，我们就要重写hashcode方法，那么这些keys的
 * hashcode值就会不同，从而减小了查找的性能损耗。
```

- **要点：如果我们创建的HashMap对象要存储大量的数据，应该给定一个初始容量。（不然内部会一直扩容，降低性能）；另外，如果有很多个key的hash值相同，有必要让这些key值实现Comparable接口。**

```
 * <p><strong>Note that this implementation is not synchronized.</strong>
 * If multiple threads access a hash map concurrently, and at least one of
 * the threads modifies the map structurally, it <i>must</i> be
 * synchronized externally.  (A structural modification is any operation
 * that adds or deletes one or more mappings; merely changing the value
 * associated with a key that an instance already contains is not a
 * structural modification.)  This is typically accomplished by
 * synchronizing on some object that naturally encapsulates the map.
 * =======================================================================
 * 注意，这个实现类是线程不安全的。如果有多个线程同时操作一个hash map，
 * 然后至少会有一个线程改变map的数据结构，那么我们必须得在外部同步进行操作。
 * （结构修改指的是增加或者删除一个或多个映射；如果仅仅是更改已经存在的
 * key和value值，不算做结构修改）。这通常需要在一个被封装好的map对象上，
 * 使用同步进行操作。
 * =======================================================================
 * If no such object exists, the map should be "wrapped" using the
 * {@link Collections#synchronizedMap Collections.synchronizedMap}
 * method.  This is best done at creation time, to prevent accidental
 * unsynchronized access to the map:<pre>
 *  Map m = Collections.synchronizedMap(new HashMap(...));</pre>
 * =========================================================================
 * 如果没有这样的对象存在，那么就需要使用Collections.synchronizedMap方法来
 * 包装这个map对象，而且最好是在创建对象的时候就进行包装，这是为了预防
 * 对这个map对象进行一些线程不同步的操作。
 * 举个例子：Map m = Collections.synchronizedMap(new HashMap(...));
```

- **要点：HashMap是一个线程不安全的类，如果要保证它的线程安全，应该使用方法**
- **Collections.synchronizedMap(new HashMap(...))来进行包装**

```
 * <p>The iterators returned by all of this class's "collection view methods"
 * are <i>fail-fast</i>: if the map is structurally modified at any time after
 * the iterator is created, in any way except through the iterator's own
 * <tt>remove</tt> method, the iterator will throw a
 * {@link ConcurrentModificationException}.  Thus, in the face of concurrent
 * modification, the iterator fails quickly and cleanly, rather than risking
 * arbitrary, non-deterministic behavior at an undetermined time in the
 * future.
 * =======================================================================
 * 该类的集合视图方法返回的迭代器是fail-fast机制的:在迭代器被创建后,如果map对象
 * 被结构化修改后,无论在何时,使用何种方法(除了迭代器本身的remove方法)来修改它,都
 * 会抛出ConcurrentModificationException.(也就是HashMap的expectedModCount和
 * modCount对不上的时候会抛出上述异常.)因此,面对并发修改操作时,迭代器会迅
 * 速且清晰地报错.而不是冒着在不确定的时间做不确定的操作的风险.	
 * ===========================================================================
 * 结论：在使用hashmap集合的时候，不要使用高级for遍历来进行增加和删除操作。
 * ===========================================================================
 * fail-fast机制
 * =========================================================================
 * “快速失败”也就是fail-fast，它是Java集合中的一种错误检测机制。某个线程在对
 *  collection进行迭代时，不允许其他线程对该collection进行结构上的修改。例如：
 *  假设存在两个线程（线程1、线程2），线程1通过Iterator在遍历集合A中的元素， 
 *  在某个时候线程2修改了集合A的结构（是结构上面的修改，而不是简单的修改集合元
 *  素的内容），那么这个时候程序就会抛出 ConcurrentModificationException 异常，
 *  从而产生fail-fast。
 * <p>Note that the fail-fast behavior of an iterator cannot be guaranteed
 * as it is, generally speaking, impossible to make any hard guarantees in the
 * presence of unsynchronized concurrent modification.  Fail-fast iterators
 * throw <tt>ConcurrentModificationException</tt> on a best-effort basis.
 * Therefore, it would be wrong to write a program that depended on this
 * exception for its correctness: <i>the fail-fast behavior of iterators
 * should be used only to detect bugs.</i>
 * ==============================================================================
 * 注意,迭代器的fail-fast行为是不能保证的.一般来说,保证非同步的同步操作是不太可能的.
 * 在最优基础上,Fail-fast迭代器会抛出ConcurrentModificationException.
 * 因此,写一个为了自身正确性而依赖于这个异常的程序是不对的.迭代器的fail-fast行为应该
 * 只是用来检测bug而已.
```

- **要点：和ArrayList的fail-fast机制一样，不在赘述**

```java
public class HashMap<K,V> extends AbstractMap<K,V>
    implements Map<K,V>, Cloneable, Serializable {

    private static final long serialVersionUID = 362498820763181265L;

 
  // The default initial capacity - MUST be a power of two.
  // =====================================================
  // 定义初始化的容量，必须是2的倍数
  // 默认值为16     1<<4---->10000---->1*2^4+0*2^3+0*2^2+0*2^1+0*2^0=16
  // 等价于static final int DEFAULT_INITIAL_CAPACITY = 16;
  
    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16    

 
     // The maximum capacity, used if a higher value is implicitly specified
     // by either of the constructors with arguments.
     // MUST be a power of two <= 1<<30.
     // ==================================
     // 定义最大容量为： 1*2^30 
     
    static final int MAXIMUM_CAPACITY = 1 << 30;

   
     // The load factor used when none specified in constructor.
     // =====================================================
     // 默认的加载因子 0.75
     // 假设未给定初始化长度，默认16.当使用put方法添加k/v值时，
     // 超过16*0.75=12时，长度会自动扩容为原来长度的两倍，也就是16*2=32；
     // 当长度增加到32*0.75=24时，继续扩容为32*2=64 。。。。。。
     

    static final float DEFAULT_LOAD_FACTOR = 0.75f;

    
     // The bin count threshold for using a tree rather than list for a
     // bin.  Bins are converted to trees when adding an element to a
     // bin with at least this many nodes. The value must be greater
     // than 2 and should be at least 8 to mesh with assumptions in
     // tree removal about conversion back to plain bins upon
     // shrinkage.
     // =================================================================
     // 定义链表转换为红黑树的长度:8
     
    static final int TREEIFY_THRESHOLD = 8;

    
     // The bin count threshold for untreeifying a (split) bin during a
     // resize operation. Should be less than TREEIFY_THRESHOLD, and at
     // most 6 to mesh with shrinkage detection under removal.
     // ==========================================================	 
     // （进行删除操作时）红黑树转换为链表结构的长度值为6
     
    static final int UNTREEIFY_THRESHOLD = 6;

    
     // The smallest table capacity for which bins may be treeified.
     // (Otherwise the table is resized if too many nodes in a bin.)
     // Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts
     // between resizing and treeification thresholds.
     // ====================================================== 
     //  当桶中的bin被树化时最小的hash表容量。
     
    static final int MIN_TREEIFY_CAPACITY = 64;

    
     // Basic hash bin node, used for most entries.  (See below for
     // TreeNode subclass, and in LinkedHashMap for its Entry subclass.)
     

    // 内部节点内
    static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        V value;
        Node<K,V> next;

        // 构造函数
        Node(int hash, K key, V value, Node<K,V> next) {
            this.hash = hash;
            this.key = key;
            this.value = value;
            this.next = next;
        }
 
        // K/V的get方法
        public final K getKey()        { return key; }
        public final V getValue()      { return value; }
        public final String toString() { return key + "=" + value; }

        // hashcode算法
        public final int hashCode() {
            return Objects.hashCode(key) ^ Objects.hashCode(value);
        }

         // V的set方法，返回原来的值
        public final V setValue(V newValue) {
            V oldValue = value;
            value = newValue;
            return oldValue;
        }

       // equal方法
        public final boolean equals(Object o) {
            if (o == this)
                return true;
            if (o instanceof Map.Entry) {
                Map.Entry<?,?> e = (Map.Entry<?,?>)o;
                if (Objects.equals(key, e.getKey()) &&
                    Objects.equals(value, e.getValue()))
                    return true;
            }
            return false;
        }
    }

   // 重新计算key的hash值 
   static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
```

> Entry是HashMap的内部类 包含四个值（next，key，value，hash），其中next是一个指向 Entry的指针，key相当于上面节点的值 value对应要保存的值，hash值由key产生，hashmap中要找到某个元素，需要根据hash值来求得对应数组中的位置，然后在由key来在链表中找Entry的位置。HashMap中的一切操作都是以Entry为基础进行的。HashMap的重点在于如何处理Entry。因此HashMap中的操作大部分都是调用Entry中的方法。可以说HashMap类本身只是提供了一个数组，和对Entry类中方法的一些封装。

```java
             
/* ---------------- Fields -------------- */

    
     // The table, initialized on first use, and resized as
     // necessary. When allocated, length is always a power of two.
     // (We also tolerate length zero in some operations to allow
     // bootstrapping mechanics that are currently not needed.)
     
    transient Node<K,V>[] table;

    
     // Holds cached entrySet(). Note that AbstractMap fields are used
     // for keySet() and values().
     
    transient Set<Map.Entry<K,V>> entrySet;

    /**
     * The number of key-value mappings contained in this map.
     */
    transient int size;

    
     // 这个数值用来定义HashMap被结构化修改的次数
     // The number of times this HashMap has been structurally modified
     // Structural modifications are those that change the number of mappings in
     // the HashMap or otherwise modify its internal structure (e.g.,
     // rehash).  This field is used to make iterators on Collection-views of
     // the HashMap fail-fast.  (See ConcurrentModificationException).
     
    transient int modCount;

    /**
     * The next size value at which to resize (capacity * load factor).
     *
     * @serial
     */
    // (The javadoc description is true upon serialization.
    // Additionally, if the table array has not been allocated, this
    // field holds the initial array capacity, or zero signifying
    // DEFAULT_INITIAL_CAPACITY.)
    int threshold;

    /**
     * The load factor for the hash table.
     *
     * @serial
     */
    final float loadFactor;
```

```java
                         构造方法
/* ---------------- Public operations -------------- */

    
     // Constructs an empty <tt>HashMap</tt> with the specified initial
     // capacity and load factor.
     
     // @param  initialCapacity the initial capacity
     // @param  loadFactor      the load factor
     // @throws IllegalArgumentException if the initial capacity is negative
     //         or the load factor is nonpositive
     
    public HashMap(int initialCapacity, float loadFactor) {
        if (initialCapacity < 0)
            throw new IllegalArgumentException("Illegal initial capacity: " +
                                               initialCapacity);
        if (initialCapacity > MAXIMUM_CAPACITY)
            initialCapacity = MAXIMUM_CAPACITY;
        if (loadFactor <= 0 || Float.isNaN(loadFactor))
            throw new IllegalArgumentException("Illegal load factor: " +
                                               loadFactor);
        this.loadFactor = loadFactor;
        this.threshold = tableSizeFor(initialCapacity);
    }

    
     // Constructs an empty <tt>HashMap</tt> with the specified initial
     // capacity and the default load factor (0.75).
     
     // @param  initialCapacity the initial capacity.
     // @throws IllegalArgumentException if the initial capacity is negative.
     
    public HashMap(int initialCapacity) {
        this(initialCapacity, DEFAULT_LOAD_FACTOR);
    }

    
     // Constructs an empty <tt>HashMap</tt> with the default initial capacity
     // (16) and the default load factor (0.75).
     
    public HashMap() {
        this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
    }

    
     // Constructs a new <tt>HashMap</tt> with the same mappings as the
     // specified <tt>Map</tt>.  The <tt>HashMap</tt> is created with
     // default load factor (0.75) and an initial capacity sufficient to
     // hold the mappings in the specified <tt>Map</tt>.
     
     // @param   m the map whose mappings are to be placed in this map
     // @throws  NullPointerException if the specified map is null
     
    public HashMap(Map<? extends K, ? extends V> m) {
        this.loadFactor = DEFAULT_LOAD_FACTOR;
        putMapEntries(m, false);
```

------

**总结：**

**1.HashMap的数据结构：数组+链表+红黑树**

![img](/img/hashmap_picture/v2-edc4a209fde826361a1283b382d08437_hd.jpg)

**2.HashMap的put方法:**

![img](/img/hashmap_picture/v2-3fd490a61bc933258aab3508cfd6d11b_hd.jpg)

①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容；

②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③；

③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals；

④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤；

⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可；

⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。

**3.get方法：计算哈希值---->找到对应的entry**